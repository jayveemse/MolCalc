{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< Updated upstream
   "id": "40d86dde-3412-44b7-adbc-332c9076a973",
=======
   "id": "2f295acc-55f5-4098-b64a-722d02e1709a",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clears out any variables, just to be safe.\n",
    "%reset -f\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import * # Keep this for constants like HORIZONTAL, W, etc.\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "from tkinter.ttk import Progressbar\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import ast\n",
    "from time import perf_counter\n",
    "from time import perf_counter_ns\n",
    "import seaborn as sns\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbd8b73a-cb33-40a5-a3be-21923a961ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global variables for file paths ---\n",
    "data_filename = \"\"\n",
    "temp_profile_file = \"\"\n",
    "layout_file = \"\"\n",
    "mating_table_file = \"\"\n",
    "fur_file = \"\"\n",
    "hps_file = \"\"\n",
    "runData = [] # This will store all final data for plotting/export\n",
    "runBool = False\n",
    "imageViewer = None # For the main Moles/P/T plot\n",
    "temp_viewer_window = None\n",
    "baselineEdited = False\n",
    "z_temp_cutoff_var = None\n",
<<<<<<< Updated upstream
    "z_offset_var = None\n",
    "p_calc_start_time_var = None\n",
    "interpolate_temps_var = None"
=======
    "z_offset_var = None"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 3,
   "id": "ee79788f-c21d-4315-9e82-55d4fc63145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fit & Uncertainty Widgets ---\n",
    "fit_start_time_var = None\n",
    "fit_end_time_var = None\n",
    "fit_results_label = None\n",
    "calculateFitButton = None\n",
    "sigma_p_var = None # <-- NEW\n",
    "sigma_v_var = None # <-- NEW\n",
    "sigma_t_var = None # <-- NEW\n",
    "# ---\n",
    "\n",
    "exportTempButton = None # Initialize button variables\n",
    "tempViewButton = None\n",
    "exportPlotButton = None\n",
    "importTempButton = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b01ebb1e-0d28-4f19-8283-801294c7eefb",
=======
   "execution_count": 2,
   "id": "f9871ce0-9330-4657-9228-1cfdabe09b2d",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- browseFiles function ---\n",
    "def browseFiles():\n",
    "    global data_filename, temp_profile_file, layout_file, mating_table_file, fur_file, hps_file, interpolate_temps_var\n",
    "\n",
    "    data_filename = filedialog.askopenfilename(\n",
    "        initialdir=os.path.expanduser('~\\\\Lehigh University Dropbox'),\n",
    "        title=\"1. Select Data CSV File\",\n",
    "        filetypes=((\"CSV files\", \"*.csv*\"), (\"all files\", \"*.*\"))\n",
    "    )\n",
    "    if data_filename: fileLabel.configure(text=f\"Data: {os.path.basename(data_filename)}\")\n",
    "    else: fileLabel.configure(text=\"Data: (Not Selected)\")\n",
    "    start_dir = os.path.dirname(data_filename) if data_filename else os.path.expanduser('~')\n",
    "\n",
    "    if not interpolate_temps_var.get(): # Only ask if checkbox is NOT checked\n",
    "        temp_profile_file = filedialog.askopenfilename(\n",
    "            initialdir=start_dir,\n",
    "            title=\"2. Select Temperature Profile CSV\", filetypes=((\"CSV files\", \"*.csv*\"),)\n",
    "        )\n",
    "        if temp_profile_file: tempLabel.configure(text=f\"Temp Profile: {os.path.basename(temp_profile_file)}\", state='normal')\n",
    "        else: tempLabel.configure(text=\"Temp Profile: (Not Selected)\", state='normal')\n",
    "    else:\n",
    "        temp_profile_file = \"\" # Clear if checkbox is checked\n",
    "        tempLabel.configure(text=\"Temp Profile: (Using Interpolation)\", state='disabled') # Indicate interpolation\n",
    "\n",
    "    layout_file = filedialog.askopenfilename(\n",
    "        initialdir=start_dir, title=\"3. Select Layout File (Excel)\", filetypes=((\"Excel files\", \"*.xlsx*\"),)\n",
    "    )\n",
    "    if layout_file: layoutLabel.configure(text=f\"Layout: {os.path.basename(layout_file)}\")\n",
    "    else: layoutLabel.configure(text=\"Layout: (Not Selected)\")\n",
    "\n",
    "    mating_table_file = filedialog.askopenfilename(\n",
    "        initialdir=start_dir, title=\"4. Select Mating Table (Excel)\", filetypes=((\"Excel files\", \"*.xlsx*\"),)\n",
    "    )\n",
    "    if mating_table_file: matingLabel.configure(text=f\"Mating Table: {os.path.basename(mating_table_file)}\")\n",
    "    else: matingLabel.configure(text=\"Mating Table: (Not Selected)\")\n",
    "\n",
    "    fur_file = filedialog.askopenfilename(\n",
    "        initialdir=start_dir, title=\"5. Select MLD - FUR (Excel)\", filetypes=((\"Excel files\", \"*.xlsx*\"),)\n",
    "    )\n",
    "    if fur_file: furLabel.configure(text=f\"MLD-FUR: {os.path.basename(fur_file)}\")\n",
    "    else: furLabel.configure(text=\"MLD-FUR: (Not Selected)\")\n",
    "\n",
    "    hps_file = filedialog.askopenfilename(\n",
    "        initialdir=start_dir, title=\"6. Select MLD - HPS (Excel)\", filetypes=((\"Excel files\", \"*.xlsx*\"),)\n",
    "    )\n",
    "    if hps_file: hpsLabel.configure(text=f\"MLD-HPS: {os.path.basename(hps_file)}\")\n",
    "    else: hpsLabel.configure(text=\"MLD-HPS: (Not Selected)\")\n",
    "\n",
    "    window.update_idletasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "937a21d7-2c39-4e64-bf54-3e5e0cc958a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Toggle Temp File Label State ---\n",
    "def toggle_temp_file_selection():\n",
    "    global interpolate_temps_var, tempLabel, temp_profile_file\n",
    "    if interpolate_temps_var.get():\n",
    "        tempLabel.configure(text=\"Temp Profile: (Using Interpolation)\", state='disabled')\n",
    "        temp_profile_file = \"\"\n",
    "    else:\n",
<<<<<<< Updated upstream
    "        tempLabel.configure(text=\"Temp Profile: (Select Below)\", state='normal')"
=======
    "        hpsLabel.configure(text=\"MLD-HPS File: (Not Selected)\")\n",
    "\n",
    "    window.update_idletasks()"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 6,
   "id": "f3478283-fee7-4d42-8a68-44e91e267719",
=======
   "execution_count": 3,
   "id": "8536cf92-04a4-4d3a-9add-3b71afe8702e",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- getData function ---\n",
    "def getData(runDF_raw, EXP_ID):\n",
    "    global graphLabel\n",
    "    print(\"running getData\")\n",
    "    config_path = os.path.expanduser(r\"~\\Lehigh University Dropbox\\ENG-MATSGroup\\MATS\\cRIO\\RunConfig\\EXPs\\\\\") + EXP_ID + '.csv'\n",
    "    print(config_path)\n",
    "    try:\n",
    "        TC_df = pd.read_csv(config_path, usecols=['Device Type', 'NI LV Channel','Shorthand Tag', 'IO Type'])\n",
    "    except FileNotFoundError: graphLabel.configure(text=f\"Error: TC config file not found for {EXP_ID}.csv\"); return None, None, None\n",
    "    except ValueError as e: graphLabel.configure(text=f\"Error: Check columns in {EXP_ID}.csv\"); return None, None, None\n",
    "    original_rows = len(TC_df); TC_df.drop_duplicates(subset=['NI LV Channel'], keep='first', inplace=True)\n",
    "    if len(TC_df) < original_rows: print(f\"Removed {original_rows - len(TC_df)} duplicate NI LV Channels.\")\n",
    "    positions = []\n",
    "    for name, type in zip(TC_df['Shorthand Tag'], TC_df['Device Type']):\n",
    "        if type == 'TC':\n",
    "            numbers_found = re.findall(r\"\\d+\", str(name))\n",
    "            if len(numbers_found) >= 2:\n",
    "                try: positions.append(int(numbers_found[1]))\n",
    "                except (ValueError, IndexError): print(f\"Warn: Bad TC tag num: '{name}'.\"); positions.append(np.nan)\n",
    "            else: print(f\"Warn: <2 nums in TC tag: '{name}'.\"); positions.append(np.nan)\n",
    "        else: positions.append(np.nan)\n",
    "    TC_df['X Position'] = positions; TC_df = TC_df.dropna(subset=['X Position'])\n",
    "    try: TC_df['X Position'] = TC_df['X Position'].astype(int)\n",
    "    except ValueError: print(\"Warn: X Pos not int.\")\n",
    "    TC_df = TC_df.sort_values(by='X Position'); TC_positions=TC_df['X Position']\n",
    "    print(\"TC_positions (valid & sorted):\", TC_positions.tolist()); print(\"TC_df (valid TCs, unique channels):\"); print(TC_df[['NI LV Channel', 'Shorthand Tag', 'X Position', 'IO Type']])\n",
    "    RelevantColumns = TC_df['NI LV Channel'].to_list()\n",
    "    if not RelevantColumns: graphLabel.configure(text=f\"Error: No valid TCs in config.\"); return None, None, None\n",
    "    unique_required_cols = list(dict.fromkeys(RelevantColumns + [\"CV1-TC-Ambient\"]))\n",
    "    missing_cols = [col for col in unique_required_cols if col not in runDF_raw.columns]\n",
    "    if missing_cols: graphLabel.configure(text=f\"Error: Data missing cols: {missing_cols}\"); return None, None, None\n",
    "    try:\n",
<<<<<<< Updated upstream
    "        runDF_selected = runDF_raw[unique_required_cols].iloc[8:]\n",
    "        print(\"Converting temperature columns to numeric...\")\n",
    "        runDF_selected = runDF_selected.apply(pd.to_numeric, errors='coerce')\n",
    "        runDF_filtered = runDF_selected.dropna()\n",
    "        if runDF_filtered.empty: graphLabel.configure(text=\"Error: No valid data rows found after filtering & coercion.\"); return None, None, None\n",
    "        print(f\"Data rows remaining after filtering: {len(runDF_filtered)}\")\n",
    "        return runDF_filtered, TC_df, TC_positions\n",
    "    except Exception as e: graphLabel.configure(text=f\"Error filtering data: {e}\"); return None, None, None\n"
=======
    "        # Select using the unique list\n",
    "        runDF_filtered = runDF[unique_required_cols][8:].dropna()\n",
    "        if runDF_filtered.empty:\n",
    "             print(\"Warning: runDF became empty after skipping rows and dropping NaNs in getData.\")\n",
    "             graphLabel.configure(text=\"Error: No valid data rows found after initial filtering.\")\n",
    "             return None, None, None\n",
    "        runDF = runDF_filtered\n",
    "    except KeyError as e:\n",
    "         graphLabel.configure(text=f\"Error: Issue selecting columns from data: {e}\")\n",
    "         return None, None, None\n",
    "    except Exception as e:\n",
    "        graphLabel.configure(text=f\"Error during data filtering: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "    return runDF, TC_df, TC_positions"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 7,
   "id": "e0ab5566-fe6a-4820-b563-89a7857ec6f6",
=======
   "execution_count": 4,
   "id": "0ebda57b-af2f-4899-9c64-516de900f78a",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- getTempProfile function ---\n",
    "def getTempProfile(temps, z_list, z_list_str, zoneBounds, zoneBoundsStr, temp_df_list):\n",
    "    profileSegments = [];\n",
    "    try: temps_float = [float(t) for t in temps]\n",
    "    except ValueError: print(\"Error: Non-numeric temp reading passed to getTempProfile.\"); return []\n",
    "    for i in range(len(z_list_str)):\n",
    "        temp_df = temp_df_list[i]; col_name = z_list_str[i]\n",
    "        if col_name not in temp_df.columns: print(f\"Error: Col '{col_name}' missing.\"); return []\n",
    "        search_column = temp_df[col_name]\n",
    "        try: idx = search_column.searchsorted(temps_float[i]); safe_idx = min(idx, len(temp_df) - 1); tempList = temp_df.iloc[safe_idx]\n",
    "        except Exception as e: print(f\"Error in search/iloc seg {i}: {e}\"); return []\n",
    "        profileSegments.append(tempList)\n",
<<<<<<< Updated upstream
    "    if not profileSegments: return []\n",
    "    try: tempProfile = pd.concat(profileSegments); tempProfile = tempProfile[~tempProfile.index.duplicated(keep='first')].tolist()\n",
    "    except Exception as e: print(f\"Error concat temp: {e}\"); return []\n",
    "    try: tempProfile = [float(t) for t in tempProfile]\n",
    "    except ValueError: print(\"Error: Non-numeric value in calculated temp profile.\"); return []\n",
=======
    "\n",
    "    if not profileSegments:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        tempProfile = pd.concat(profileSegments)\n",
    "        tempProfile = tempProfile[~tempProfile.index.duplicated(keep='first')].tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during pd.concat in getTempProfile: {e}\")\n",
    "        return []\n",
    "\n",
>>>>>>> Stashed changes
    "    return tempProfile"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 8,
   "id": "c0a52130-840a-41be-9241-0ef11af6db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- interpolateTempProfile function ---\n",
    "def interpolateTempProfile(current_temps, tc_positions_series):\n",
    "    \"\"\"Linearly interpolates temperatures based on a 3-point profile.\"\"\"\n",
    "    try: temps_float = [float(t) for t in current_temps]\n",
    "    except ValueError: print(\"Error: Non-numeric temp reading passed to interpolate.\"); return []\n",
    "    if len(temps_float) != len(tc_positions_series): print(\"Error: Temps/Positions mismatch in interpolation.\"); return []\n",
    "    try: x_known_values = tc_positions_series.astype(float).values\n",
    "    except ValueError: print(\"Error: TC positions not convertible to float.\"); return []\n",
    "    sorted_indices = np.argsort(x_known_values); x_known = x_known_values[sorted_indices]; y_known = np.array(temps_float)[sorted_indices]\n",
    "    min_pos = x_known[0]; min_temp = y_known[0]; max_pos = x_known[-1]; max_temp = y_known[-1]\n",
    "    peak_temp = np.max(y_known); peak_pos = x_known[np.argmax(y_known)]\n",
    "    interp_data = {min_pos: min_temp, peak_pos: peak_temp, max_pos: max_temp}\n",
    "    x_final_pts = sorted(interp_data.keys()); y_final_pts = [interp_data[x] for x in x_final_pts]\n",
    "    if len(x_final_pts) < 2: print(f\"Warn: Only one unique TC pos ({x_final_pts}).\"); return [y_final_pts[0]] * (int(max_pos - min_pos) + 1 if max_pos > min_pos else 10)\n",
    "    x_target = np.arange(int(min_pos), int(max_pos) + 1)\n",
    "    interpolated_temps = np.interp(x_target, x_final_pts, y_final_pts)\n",
    "    return interpolated_temps.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58749222-cf76-4961-90bb-14d8b5bc088b",
=======
   "execution_count": 5,
   "id": "c6a3a261-a5c9-4abc-a9c6-342c9e9ca87b",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- getPartVolProfile function ---\n",
    "def getPartVolProfile(data):\n",
    "    APdata = data[\"Axial Position (mm)\"]; CSdata=data[\"Cross-Sectional Area (mm^2)\"]; TMdata=data[\"Transition Model\"]\n",
    "    areaProfile = []\n",
    "    for i in range(len(APdata)-1):\n",
    "        x = np.arange(APdata[i], APdata[i+1], 0.1)\n",
    "        if TMdata[i] != 'Constant':\n",
    "            try: sectionAreaProfile = eval(TMdata[i])\n",
    "            except Exception as e: print(f\"Error eval TM '{TMdata[i]}': {e}\"); sectionAreaProfile = np.full((1,len(x)), CSdata[i])[0]\n",
    "        else: sectionAreaProfile = np.full((1,len(x)), CSdata[i])[0]\n",
    "        areaProfile.append(sectionAreaProfile)\n",
    "    areaProfile.append(np.array([CSdata[-1]])); areaProfile = np.concatenate(areaProfile)\n",
    "    volumeProfile = [0.1*slice for slice in areaProfile]\n",
    "    return volumeProfile"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 10,
   "id": "89c7879c-5144-47d1-b558-8017c1549a07",
=======
   "execution_count": 6,
   "id": "6c3543f4-0984-4855-be8b-3923430ce08f",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- getSystemVolumeProfile function ---\n",
    "def getSystemVolumeProfile(partList, mating_table_path, fur_path, hps_path):\n",
    "    global graphLabel; isReversed = False; previousIsReversed = False; cumulativeOffset = 0\n",
    "    try:\n",
    "        planeTable = pd.read_excel(mating_table_path)\n",
    "        furnitureDict = pd.read_excel(fur_path, sheet_name=['CRU', 'LID', 'PLU', 'VRE', 'TUB'])\n",
    "        HPSDict = pd.read_excel(hps_path, sheet_name=['AC', 'GKT', 'NZ'])\n",
    "    except Exception as e: graphLabel.configure(text=f\"Error reading geometry: {e}\"); return None\n",
    "    CRU, LID, PLU, VRE, TUB = [sheet[[\"UID\", \"Profile\"]].dropna() for sheet, key in zip(furnitureDict.values(), furnitureDict.keys())]\n",
    "    AC, GKT, NZ = [sheet[[\"UID\", \"Profile\"]].dropna() for sheet, key in zip(HPSDict.values(), HPSDict.keys())]\n",
    "    partsDF = pd.concat([CRU,LID,PLU,VRE,AC,GKT,NZ,TUB], ignore_index=True)\n",
    "    def safe_parse_profile(profile):\n",
    "        if isinstance(profile, str):\n",
    "            profile = profile.strip();\n",
    "            if profile.endswith(\"'\") or profile.endswith('\"'): profile = profile[:-1]\n",
    "            if profile.startswith(\"'\") or profile.startswith('\"'): profile = profile[1:]\n",
    "            try: return ast.literal_eval(profile)\n",
    "            except Exception as e: raise ValueError(f\"Invalid profile string: {profile}\") from e\n",
    "        return profile\n",
    "    partList = partList.dropna(); relevantParts = pd.DataFrame(columns=['UID', 'Profile'])\n",
    "    for index, row in partList.iterrows(): partProfile = partsDF.loc[partsDF['UID'] == row['UID']];\n",
    "    if len(partProfile)!=0: relevantParts=pd.concat([relevantParts, partProfile], ignore_index=True)\n",
    "    if relevantParts.empty: graphLabel.configure(text=\"Error: No relevant parts found.\"); return None\n",
    "    part_series_dict = {}; mate_positions = []; partVolumes = {}; placement_summaries = []\n",
    "    if relevantParts.empty: graphLabel.configure(text=\"Error: No parts to process.\"); return None\n",
    "\n",
    "    # Handle Single Part Case\n",
    "    if len(relevantParts) == 1:\n",
    "        print(\"Processing single part...\")\n",
    "        try:\n",
    "            single_part_data = safe_parse_profile(relevantParts[\"Profile\"].iloc[0])\n",
    "            if not isinstance(single_part_data, dict): raise ValueError(\"Parsed profile is not a dictionary\")\n",
    "            single_part_volume = getPartVolProfile(single_part_data)\n",
    "            uid0 = str(relevantParts[\"UID\"].iloc[0])\n",
    "            colName0 = f\"Part_0_{uid0}\"\n",
    "            slice_idx0 = list(range(len(single_part_volume)))\n",
    "            if slice_idx0: part_series_dict[colName0] = pd.Series(single_part_volume, index=slice_idx0); cumulativeOffset = (len(slice_idx0) - 1) / 10.0; mate_positions.append({\"Part\": colName0, \"Previous Mate Position\": 0.0, \"Next Mate Position\": None})\n",
    "            else: cumulativeOffset = 0.0; graphLabel.configure(text=\"Warning: Single part has zero length/volume.\")\n",
    "        except Exception as e: error_msg = f\"Error processing single part ({relevantParts['UID'].iloc[0]}): {e}\"; print(error_msg); graphLabel.configure(text=error_msg); return None\n",
    "    else: # Process multiple parts\n",
    "        uid0 = str(relevantParts[\"UID\"].iloc[0]); mate_positions.append({\"Part\":f\"Part_0_{uid0}\", \"Previous Mate Position\": None, \"Next Mate Position\": None})\n",
    "        for i in range(len(relevantParts) - 1):\n",
    "            try:\n",
    "                previousPart = safe_parse_profile(relevantParts[\"Profile\"].iloc[i]); nextPart = safe_parse_profile(relevantParts[\"Profile\"].iloc[i + 1])\n",
    "                if not isinstance(previousPart, dict) or not isinstance(nextPart, dict): raise ValueError(f\"Profile not dict idx {i}/{i+1}\")\n",
    "                previousPartPlanes = previousPart.get('Contact Plane'); nextPartPlanes = nextPart.get('Contact Plane')\n",
    "                if previousPartPlanes is None or nextPartPlanes is None: raise KeyError(f\"'Contact Plane' missing {i}/{i+1}\")\n",
    "                nextPartPlanesReversed = [''.join([c if c!='^' and c!='v' else '^' if c=='v' else 'v' for c in p]) for p in reversed(nextPartPlanes)]\n",
    "                previousPartAxialPositions = previousPart.get('Axial Position (mm)'); nextPartAxialPositions = nextPart.get('Axial Position (mm)')\n",
    "                if previousPartAxialPositions is None or nextPartAxialPositions is None: raise KeyError(f\"'Axial Position' missing {i}/{i+1}\")\n",
    "                previousPartVolumeProfile = getPartVolProfile(previousPart)\n",
    "                if i==0:\n",
    "                    colName0 = f\"Part_0_{uid0}\"; idx0 = list(range(len(previousPartVolumeProfile)))\n",
    "                    if idx0: part_series_dict[colName0] = pd.Series(previousPartVolumeProfile, index=idx0); cumulativeOffset = (len(idx0)-1)/10.0\n",
    "                    else: cumulativeOffset = 0.0\n",
    "                if isReversed:\n",
    "                    previousPartPlanes = [''.join([c if c!='^' and c!='v' else '^' if c=='v' else 'v' for c in p]) for p in reversed(previousPartPlanes)]\n",
    "                    previousPartAxialPositions.reverse(); previousPartVolumeProfile.reverse(); previousIsReversed = True\n",
    "                mateList = []\n",
    "                for plane in previousPartPlanes: matches = planeTable.loc[planeTable['Plane'] == plane];\n",
    "                if not matches.empty and 'Valid Mates' in matches.columns: mates_str = matches['Valid Mates'].iloc[-1]; mateList.append(mates_str.split(', ') if pd.notna(mates_str) else [])\n",
    "                else: mateList.append([])\n",
    "                normalMates = []; reversedMates = []\n",
    "                for j in reversed(range(len(mateList))):\n",
    "                    is_rest = lambda s: \"REST\" in str(s).upper(); nn = [c for c in normalMates if not is_rest(c[0])]; rr = [c for c in reversedMates if not is_rest(c[0])]\n",
    "                    if nn or rr: normalMates, reversedMates = nn, rr\n",
    "                    for k in range(len(nextPartPlanes)):\n",
    "                        if nextPartPlanes[k] in mateList[j]: normalMates.append([previousPartPlanes[j], j, nextPartPlanes[k], k])\n",
    "                    for k in range(len(nextPartPlanesReversed)):\n",
    "                        if nextPartPlanesReversed[k] in mateList[j]: reversedMates.append([previousPartPlanes[j], j, nextPartPlanesReversed[k], k])\n",
    "                if len(normalMates) > 0 and len(reversedMates) == 0: validMateList = normalMates[0]; isReversed = False\n",
    "                elif len(reversedMates) > 0 and len(normalMates) == 0: validMateList = reversedMates[0]; isReversed=True; print(f\"Reversed: {relevantParts['UID'].iloc[i+1]}\")\n",
    "                elif len(normalMates)>0 and len(reversedMates)>0:\n",
    "                    jn, jr = normalMates[0][1], reversedMates[0][1]\n",
    "                    if any(x in relevantParts[\"UID\"].iloc[i+1] for x in [\"AC\",\"GKT\",\"GPA\"]): validMateList=normalMates[0]\n",
    "                    elif jr == jn: validMateList = normalMates[0]; isReversed = False\n",
    "                    elif jr != jn:\n",
    "                        if jr > jn: validMateList = reversedMates[0]; isReversed = True; print(f\"Reversed (top): {relevantParts['UID'].iloc[i+1]}\")\n",
    "                        else: validMateList = normalMates[0]; isReversed = False\n",
    "                    elif any([any(x in str(p) for x in ['GASK','ORING']) for p in normalMates]): validMateList=normalMates[0]; isReversed=False\n",
    "                    elif any([any(x in str(p) for x in ['GASK','ORING']) for p in reversedMates]): validMateList=reversedMates[0]; isReversed=True; print(f\"Reversed (gask): {relevantParts['UID'].iloc[i+1]}\")\n",
    "                    else: validMateList = normalMates[0]; isReversed = False\n",
    "                else: raise ValueError(f\"No valid mates for {relevantParts['UID'].iloc[i+1]} to {relevantParts['UID'].iloc[i]}.\")\n",
    "                nextPartVolumeProfile = getPartVolProfile(nextPart); partVolume_mm3 = np.sum(nextPartVolumeProfile); partVolumes[relevantParts['UID'].iloc[i+1]] = partVolume_mm3\n",
    "                if isReversed: nextPartAxialPositions.reverse(); x_max = max(nextPartAxialPositions); nextPartAxialPositions = [x_max-x for x in nextPartAxialPositions]; nextPartVolumeProfile.reverse()\n",
    "                j = validMateList[1]; k = validMateList[3]; prev_part_end = max(previousPartAxialPositions); next_start = min(nextPartAxialPositions)\n",
    "                if previousIsReversed: d_prev = previousPartAxialPositions[j]\n",
    "                else: d_prev = prev_part_end - previousPartAxialPositions[j]\n",
    "                d_next = nextPartAxialPositions[k]\n",
    "                if previousPartAxialPositions[j] == prev_part_end and nextPartAxialPositions[k] == next_start: part_Offset = 0.0\n",
    "                else: part_Offset = d_prev + d_next\n",
    "                part_length = (len(nextPartVolumeProfile)-1)/10.0; start_pos = cumulativeOffset - part_Offset; next_mate = round(start_pos + nextPartAxialPositions[k],3)\n",
    "                next_part_uid = relevantParts['UID'].iloc[i+1]; colName = f\"Part_{i+1}_{next_part_uid}\"\n",
    "                slice_idx = [int(round(10 * start_pos)) + num for num in range(len(nextPartVolumeProfile))]\n",
    "                if slice_idx: part_series_dict[colName] = pd.Series(nextPartVolumeProfile, index=slice_idx)\n",
    "                uid_prev = relevantParts['UID'].iloc[i]; summary = [(f\"{uid_prev} @ {next_mate} mm\"),(f\"{validMateList[0]}->{validMateList[2]}\")]; placement_summaries.append(summary)\n",
    "                if i == 0: mate_positions[0][\"Previous Mate Position\"] = 0.00\n",
    "                mate_positions.append({\"Part\": f\"Part_{i+1}_{next_part_uid}\",\"Previous Mate Position\": start_pos,\"Next Mate Position\": next_mate})\n",
    "                mate_positionsDF = pd.DataFrame(mate_positions).reset_index(drop=True)\n",
    "                cumulativeOffset = start_pos + part_length\n",
    "            except Exception as e: error_msg = f\"Error part {i+1} ({relevantParts['UID'].iloc[i+1]}): {e}\"; print(error_msg); graphLabel.configure(text=error_msg); return None\n",
    "\n",
    "    if not part_series_dict: graphLabel.configure(text=\"Error: No part data generated.\"); return None\n",
    "    try: volumeDF = pd.DataFrame(part_series_dict)\n",
    "    except Exception as e: graphLabel.configure(text=f\"Error creating vol DF: {e}\"); return None\n",
    "    volumeDF.sort_index(inplace=True); volumeDF.fillna(0, inplace=True); volumeDF[\"Axial Position\"] = volumeDF.index * 0.1; volumeDF[\"Total Volume\"] = volumeDF.iloc[:, :-1].sum(axis=1)\n",
    "\n",
    "    if len(relevantParts) > 1:\n",
    "        print(\"\\nPLACEMENT SUMMARY:\"); print(\"-\" * 60); [print(f\"{p}\\n{m}\\n{'-'*60}\") for p, m in placement_summaries]\n",
    "        print(\"\\nMate Positions\"); print(mate_positionsDF)\n",
    "    print(\"\\nVolume per part (mL):\")\n",
    "    [print(f\"{col}: {volumeDF[col].sum()/1000:.3f} mL\") for col in part_series_dict.keys() if col in volumeDF]\n",
    "    print('\\npartList:', partList); volumeDF.to_csv('volumeDF_AC-TG.csv', index=True)\n",
    "\n",
    "    plot_cols = list(part_series_dict.keys())\n",
    "    if not plot_cols: print(\"Warning: No 'Part' columns found for plotting.\")\n",
    "    for col in plot_cols:\n",
    "        try:\n",
<<<<<<< Updated upstream
    "             y_data = volumeDF[col]; x_data = volumeDF[\"Axial Position\"]\n",
    "             if not (x_data.empty or y_data.empty or (y_data == 0).all()):\n",
    "                 fig=go.Figure(); fig.add_trace(go.Scatter(x=x_data, y=y_data)); fig.update_layout(title=f\"Vol: {col}\"); fig.show()\n",
    "        except Exception as e: print(f\"Err plot {col}: {e}\")\n",
=======
    "             not_nan = volumeDF[col].notna()\n",
    "             if not not_nan.any():\n",
    "                  print(f\"Skipping plot for {col}: all NaN values.\")\n",
    "                  continue\n",
    "\n",
    "             y_data = volumeDF.loc[not_nan, col]\n",
    "             x_data = volumeDF.loc[not_nan, \"Axial Position\"]\n",
    "\n",
    "             if x_data.empty or y_data.empty:\n",
    "                  print(f\"Skipping plot for {col}: no valid data points.\")\n",
    "                  continue\n",
    "\n",
    "\n",
    "             fig = go.Figure()\n",
    "             fig.add_trace(go.Bar(x=x_data, y=y_data, marker_color='lightcoral'))\n",
    "             fig.update_layout(\n",
    "                 title=f\"Volume Profile of {col}\",\n",
    "                 xaxis_title='Axial Positions (mm)',\n",
    "                 yaxis_title='Volume(mm^3) per 0.1mm Slice',\n",
    "                 hovermode='x unified',\n",
    "                 template='plotly_white',\n",
    "                 width = 1300,\n",
    "                 height = 600,\n",
    "                 xaxis_range=[x_data.min() if not x_data.empty else 0, x_data.max() if not x_data.empty else 1]\n",
    "             )\n",
    "             fig.update_yaxes(exponentformat='power')\n",
    "             fig.show()\n",
    "        except Exception as e:\n",
    "             print(f\"Error plotting per-part volume for {col}: {e}\")\n",
    "\n",
    "\n",
>>>>>>> Stashed changes
    "    try:\n",
    "         x_values = volumeDF[\"Axial Position\"]; y_data = volumeDF[\"Total Volume\"]\n",
    "         if not (x_values.empty or y_data.empty or (y_data==0).all()):\n",
    "             fig=go.Figure(); fig.add_trace(go.Scatter(x=x_values, y=y_data, name='Total')); [fig.add_vline(x=p.get(\"Next Mate Position\"),line_dash=\"dash\") for p in mate_positions if p.get(\"Next Mate Position\") is not None]; fig.update_layout(title='Total Volume'); fig.show()\n",
    "    except Exception as e: print(f\"Err plot total: {e}\")\n",
    "\n",
<<<<<<< Updated upstream
=======
    "         if x_values.empty or y_data.empty or y_data.isna().all():\n",
    "              print(\"Warning: No valid data for plotting total system volume.\")\n",
    "\n",
    "         else:\n",
    "              fig = go.Figure()\n",
    "              fig.add_trace(go.Bar(x=x_values, y=y_data, name='Total Volume Profile', marker_color='lightcoral'))\n",
    "              for pos_dict in mate_positions:\n",
    "                  pos = pos_dict.get(\"Next Mate Position\")\n",
    "                  if pos is not None:\n",
    "                      fig.add_vline(x=pos, line_dash=\"dash\", line_color=\"black\", line_width=1)\n",
    "\n",
    "              fig.update_layout(\n",
    "                  title='System Volume Along Z-axis',\n",
    "                  xaxis_title='Axial Positions (mm)',\n",
    "                  yaxis_title='Volume(mm^3) per 0.1mm Slice',\n",
    "                  hovermode='x unified',\n",
    "                  template='plotly_white',\n",
    "                  width = 1300,\n",
    "                  height = 600\n",
    "              )\n",
    "\n",
    "              fig.update_yaxes(exponentformat='power')\n",
    "              fig.show()\n",
    "    except Exception as e:\n",
    "         print(f\"Error plotting total system volume: {e}\")\n",
    "\n",
    "\n",
>>>>>>> Stashed changes
    "    return volumeDF"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 11,
   "id": "1d6bb84f-f172-4146-b24e-629660ad8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- processData function ---\n",
=======
   "execution_count": 7,
   "id": "cf9ee356-54c6-49bb-9cc5-af2ba625e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MODIFIED: processData function ---\n",
>>>>>>> Stashed changes
    "def processData():\n",
    "    global runData, baselineEdited, graphLabel, fileProgress, graphProgress\n",
    "    global data_filename, temp_profile_file, layout_file, mating_table_file, fur_file, hps_file\n",
    "    global z_temp_cutoff_var, z_offset_var, p_calc_start_time_var, interpolate_temps_var\n",
    "    global exportTempButton, tempViewButton, exportPlotButton, calculateFitButton, fit_results_label\n",
    "    global sigma_p_var, sigma_v_var, sigma_t_var # <-- NEW\n",
    "\n",
    "    if exportPlotButton: exportPlotButton.configure(state='disabled')\n",
    "    if exportTempButton: exportTempButton.configure(state='disabled')\n",
    "    if tempViewButton: tempViewButton.configure(state='disabled')\n",
    "    if calculateFitButton: calculateFitButton.configure(state='disabled')\n",
    "    if fit_results_label: fit_results_label.configure(text=\"\")\n",
    "\n",
    "    if not data_filename: graphLabel.configure(text=\"Error: Select Data File.\"); return\n",
    "    use_interpolation = interpolate_temps_var.get()\n",
    "    if not use_interpolation and not temp_profile_file: graphLabel.configure(text=\"Error: Select Temp Profile or check Interpolate.\"); return\n",
    "    if not layout_file: graphLabel.configure(text=\"Error: Select Layout File.\"); return\n",
    "    if not mating_table_file: graphLabel.configure(text=\"Error: Select Mating Table.\"); return\n",
    "    if not fur_file: graphLabel.configure(text=\"Error: Select MLD-FUR File.\"); return\n",
    "    if not hps_file: graphLabel.configure(text=\"Error: Select MLD-HPS File.\"); return\n",
    "\n",
    "    z_temp_cutoff_mm = None\n",
    "    try: \n",
    "        z_cutoff_input = z_temp_cutoff_var.get();\n",
    "        if z_cutoff_input: z_temp_cutoff_mm = int(float(z_cutoff_input)); print(f\"Using Z-Temp Cutoff: {z_temp_cutoff_mm} mm\")\n",
    "    except ValueError: \n",
    "        graphLabel.configure(text=\"Error: Invalid Z-Temp Cutoff.\"); return\n",
    "\n",
    "    z_offset_mm = 0\n",
    "    try: \n",
    "        z_offset_input = z_offset_var.get();\n",
    "        if z_offset_input: z_offset_mm = int(float(z_offset_input)); print(f\"Applying Z-Offset: {z_offset_mm} mm\")\n",
    "    except ValueError: \n",
    "        graphLabel.configure(text=\"Error: Invalid Z-Offset.\"); return\n",
    "\n",
    "    p_calc_start_hr = None\n",
    "    try: \n",
    "        start_time_input = p_calc_start_time_var.get();\n",
    "        if start_time_input: p_calc_start_hr = float(start_time_input); print(f\"Using P_calc Start Time: {p_calc_start_hr} Hours\")\n",
    "        else: print(\"P_calc Start Time not provided.\")\n",
    "    except ValueError: \n",
    "        graphLabel.configure(text=f\"Error: Invalid P_calc Start Time '{start_time_input}'.\"); return\n",
    "\n",
    "    # --- NEW: Get Uncertainty Inputs ---\n",
    "    try:\n",
    "        sigma_p_percent = float(sigma_p_var.get()) / 100.0 # Convert from % to fraction\n",
    "        sigma_v_percent = float(sigma_v_var.get()) / 100.0 # Convert from % to fraction\n",
    "        sigma_t_base_K = float(sigma_t_var.get()) # Absolute K\n",
    "        print(f\"Uncertainty Assumptions: P={sigma_p_percent*100}%, V={sigma_v_percent*100}%, T={sigma_t_base_K} K\")\n",
    "    except ValueError:\n",
    "        graphLabel.configure(text=\"Error: Invalid uncertainty values. Must be numbers.\"); return\n",
    "    # --- END NEW ---\n",
    "\n",
    "\n",
    "    fileProgress.grid(row=23, column=3); fileProgress['value']=0; window.update_idletasks()\n",
    "\n",
    "    try: df = pd.read_csv(data_filename, low_memory=False)\n",
    "    except Exception as e: graphLabel.configure(text=f\"Error reading Data: {e}\"); return\n",
    "    fileProgress['value'] = 10; window.update_idletasks()\n",
    "\n",
    "    if df.shape[0] <= 12 or df.shape[1] <= 20: graphLabel.configure(text=\"Error: Data format unexpected.\"); return\n",
    "    runID = df.iloc[12,10]; EXP_ID = df.iloc[6, 20]\n",
    "    print(f\"Run ID: {runID}, EXP ID: {EXP_ID}\")\n",
    "\n",
    "    runDF_filtered, TC_df, TC_positions = getData(df.copy(), EXP_ID)\n",
    "    if runDF_filtered is None: return\n",
    "\n",
    "    print(\"Resetting runDF index...\"); runDF = runDF_filtered.reset_index(drop=True); print(\"Index reset.\")\n",
    "    fileProgress['value'] = 20; window.update_idletasks()\n",
    "\n",
    "    # Pressure Processing\n",
    "    pressure_col = None; P_MPa = []; P_MPa_series = None\n",
    "    if 'CVFP-PT-CV-A2' in df.columns: pressure_col = 'CVFP-PT-CV-A2'\n",
    "    elif 'CVFP-PT-CV-A' in df.columns: pressure_col = 'CVFP-PT-CV-A'\n",
    "    elif 'CVFP-PT-CV-A3' in df.columns: pressure_col = 'CVFP-PT-CV-A3'\n",
    "    if pressure_col is None: graphLabel.configure(text=\"Error: Pressure column not found.\"); return\n",
    "    try:\n",
    "        print(f\"Using pressure column: {pressure_col}\")\n",
    "        P_MPa_series = df.loc[runDF_filtered.index, pressure_col].astype(float)\n",
    "        if P_MPa_series.isna().all(): graphLabel.configure(text=f\"Error: All pressure data is invalid.\"); return\n",
    "        P_MPa = P_MPa_series.tolist()\n",
    "    except Exception as e: graphLabel.configure(text=f\"Error processing pressure: {e}\"); return\n",
    "    print(f\"Pressure points: {len(P_MPa)}\"); P_Pa=[float(p)*1e6 for p in P_MPa if pd.notna(p)]; fileProgress['value'] = 30; window.update_idletasks()\n",
    "\n",
    "    # Time Processing (Aligned with runDF)\n",
    "    if 'Relative.2' not in df.columns: graphLabel.configure(text=\"Error: Time column 'Relative.2' missing.\"); return\n",
    "    Time_Minutes = []; Time_Seconds = pd.Series([], dtype=float); Time_Hours = pd.Series([], dtype=float)\n",
    "    try:\n",
    "        time_series_full = df['Relative.2']\n",
    "        Time_Minutes_series = time_series_full.loc[runDF_filtered.index]\n",
    "        if len(Time_Minutes_series) != len(runDF): graphLabel.configure(text=\"Error: Time/runDF length mismatch.\"); return\n",
    "        Time_Minutes = Time_Minutes_series.tolist()\n",
    "        Time_Seconds= pd.Series([float(min)*60 for min in Time_Minutes], index=runDF.index)\n",
    "        Time_Hours= pd.Series([float(min)/60 for min in Time_Minutes], index=runDF.index)\n",
    "        print(f\"Time points: {len(Time_Minutes)}\")\n",
    "    except Exception as e: graphLabel.configure(text=f\"Error processing time: {e}\"); return\n",
    "    if not Time_Minutes: graphLabel.configure(text=\"Error: No time data after alignment.\"); return\n",
    "    fileProgress['value'] = 40; window.update_idletasks()\n",
    "\n",
    "\n",
    "    # Volume Profile Processing\n",
    "    try: partList=pd.read_excel(layout_file)\n",
    "    except Exception as e: graphLabel.configure(text=f\"Error reading Layout: {e}\"); return\n",
    "    volumeDF = getSystemVolumeProfile(partList, mating_table_file, fur_file, hps_file)\n",
    "    if volumeDF is None: return\n",
    "    if 'Total Volume' not in volumeDF or volumeDF['Total Volume'].isna().all(): graphLabel.configure(text=\"Error: Total Volume calc failed.\"); return\n",
    "    coarseVol_series = volumeDF['Total Volume']; remainder = len(coarseVol_series) % 10\n",
    "    if remainder != 0: padding = pd.Series([0]*(10-remainder), index=range(len(coarseVol_series), len(coarseVol_series)+10-remainder)); coarseVol_series=pd.concat([coarseVol_series,padding])\n",
    "    coarseVol = []; volumeProfile_padded = coarseVol_series.tolist()\n",
    "    for i in range(int(len(volumeProfile_padded) / 10)): coarseVol.append(sum(volumeProfile_padded[10*i : 10*(i+1)]))\n",
    "    if not coarseVol: graphLabel.configure(text=\"Error: Coarse volume calc failed.\"); return\n",
    "    coarseVol = [vol / 1e9 for vol in coarseVol]; coarseVol_mL = [v*1e6 for v in coarseVol]\n",
    "    V_total_m3 = sum(coarseVol)\n",
    "    print(f\"\\nTotal Vol (mL): {volumeDF['Total Volume'].sum()/1000:.3f} (DF), {sum(coarseVol_mL):.3f} (Coarse), Total Vol (m^3): {V_total_m3:.3e}\")\n",
    "    fileProgress['value'] = 50; window.update_idletasks()\n",
    "\n",
    "    # Temperature Profile Setup (Conditional)\n",
    "    lookupTable = None; temp_df_list = None; z_min_cal = None; z_max_cal = None; zoneBoundsStr = None; z_list_str = None; z_list = None; zoneBounds = None\n",
    "    if not use_interpolation:\n",
    "        print(\"Using Temperature Profile CSV...\")\n",
    "        try: lookupTable = pd.read_csv(temp_profile_file, index_col=0)\n",
    "        except Exception as e: graphLabel.configure(text=f\"Error reading Temp Profile: {e}\"); return\n",
    "        try: lookupTable.columns = [str(int(float(c))) for c in lookupTable.columns]\n",
    "        except ValueError: graphLabel.configure(text=\"Error: Temp Profile columns not numbers.\"); return\n",
    "        try:\n",
    "            if len(lookupTable.columns) < 2: raise IndexError(\"Temp Profile < 2 columns.\")\n",
    "            z_min_cal = int(lookupTable.columns[1]); z_max_cal = int(lookupTable.columns[-1])\n",
    "            print(f\"Temp cal range from CSV: {z_min_cal}mm to {z_max_cal}mm\")\n",
    "        except (IndexError, ValueError) as e: graphLabel.configure(text=f\"Error reading Temp Profile range: {e}\"); return\n",
    "        if TC_positions.empty: graphLabel.configure(text=\"Error: No valid TC positions.\"); return\n",
    "        z_list_cal = sorted(set([z_min_cal] + TC_positions.tolist() + [z_max_cal]))\n",
    "        z_list_cal = [float(f\"{int(z):.1f}\") for z in z_list_cal]\n",
    "        zoneBounds = [z_list_cal[0]] + [round(0.5*(z_list_cal[i]+z_list_cal[i+1])) for i in range(1, len(z_list_cal)-1)] + [z_list_cal[-1]]\n",
    "        zoneBounds = [float(f\"{int(b):.1f}\") for b in zoneBounds]; zoneBoundsStr = [str(int(round(b))) for b in zoneBounds]\n",
    "        z_list = z_list_cal[1:]; z_list_str = [str(int(round(x))) for x in z_list_cal[1:]]\n",
    "        print(\"z_list_str (first 20, from CSV):\", z_list_str[:20])\n",
    "        temp_df_list = []\n",
    "        for i in range(len(z_list_str)):\n",
    "            start_col = zoneBoundsStr[i]; end_col = zoneBoundsStr[i+1]\n",
    "            if start_col not in lookupTable.columns: graphLabel.configure(text=f\"Error: Temp file missing col: '{start_col}'\"); return\n",
    "            if end_col not in lookupTable.columns: graphLabel.configure(text=f\"Error: Temp file missing col: '{end_col}'\"); return\n",
    "            try: temp_df = lookupTable.loc[:, start_col:end_col]; temp_df = temp_df.sort_values(by=[z_list_str[i]]); temp_df_list.append(temp_df)\n",
    "            except Exception as e: graphLabel.configure(text=f\"Error processing Temp slice {i}: {e}\"); return\n",
    "    else:\n",
    "        print(\"Using Linear Interpolation for Temperature Profile...\")\n",
    "        if TC_positions.empty: graphLabel.configure(text=\"Error: No TC positions for interpolation.\"); return\n",
    "        z_min_cal = int(TC_positions.min()); z_max_cal = int(TC_positions.max())\n",
    "        print(f\"Interpolation range: {z_min_cal}mm to {z_max_cal}mm\")\n",
    "    fileProgress['value'] = 60; window.update_idletasks()\n",
    "\n",
    "    # Main Calculation Loop\n",
    "    graphProgress.grid(row=23, column=2, sticky=W); graphProgress['value']=0; window.update_idletasks()\n",
    "    n=[]; avgTempList = []; full_temp_profiles_K = []; n_error_list = [] # <-- NEW: Init error list\n",
    "    R=8.3145\n",
    "    required_tc_channels = TC_df['NI LV Channel'].tolist()\n",
    "    runTempsDF = runDF[required_tc_channels]\n",
    "    if runTempsDF.empty: graphLabel.configure(text=\"Error: No temperature data.\"); return\n",
    "\n",
    "    print(\"Starting main calculation loop...\")\n",
    "    for i in range(len(runDF)):\n",
    "        try:\n",
    "            temps = runTempsDF.iloc[i].tolist() # Already float\n",
    "            if use_interpolation: tempProfile_raw = interpolateTempProfile(temps, TC_positions)\n",
    "            else: tempProfile_raw = getTempProfile(temps, z_list, z_list_str, zoneBounds, zoneBoundsStr, temp_df_list)\n",
    "            if not tempProfile_raw: print(f\"Warn: Temp profile empty step {i}.\"); avgTempList.append(np.nan); n.append(np.nan); full_temp_profiles_K.append([]); n_error_list.append(np.nan); continue # Append NaN to all\n",
    "            if len(tempProfile_raw) > 0: avgTempList.append(sum(tempProfile_raw)/len(tempProfile_raw))\n",
    "            else: avgTempList.append(np.nan)\n",
    "            tempProfile = [temp + 273.15 for temp in tempProfile_raw] # To Kelvin\n",
    "\n",
    "            ambient_val = runDF[\"CV1-TC-Ambient\"].iloc[i] # Already float/NaN\n",
    "            ambient_temp = ambient_val + 273.15 if pd.notna(ambient_val) else 298.15\n",
    "\n",
    "            tempProfile_cutoff = tempProfile[:]\n",
    "            if z_temp_cutoff_mm is not None:\n",
    "                profile_start_z = 0 if not use_interpolation else z_min_cal\n",
    "                cutoff_index = z_temp_cutoff_mm - profile_start_z\n",
    "                if cutoff_index < 0: cutoff_index = 0\n",
    "                if cutoff_index < len(tempProfile_cutoff): tempProfile_cutoff = tempProfile_cutoff[:cutoff_index]\n",
    "                elif cutoff_index > len(tempProfile_cutoff):\n",
    "                    if tempProfile_cutoff: fill_needed = cutoff_index - len(tempProfile_cutoff); tempProfile_cutoff.extend([tempProfile_cutoff[-1]] * fill_needed)\n",
    "\n",
    "            if not tempProfile_cutoff: last_cal_temp = ambient_temp\n",
    "            else: last_cal_temp = float(tempProfile_cutoff[-1])\n",
    "            temp_gradient = np.linspace(last_cal_temp, ambient_temp, 50); tempProfile_cutoff.extend(temp_gradient)\n",
    "            if len(coarseVol)>len(tempProfile_cutoff): tempProfile_cutoff += [ambient_temp]*((len(coarseVol)-len(tempProfile_cutoff)))\n",
    "            full_temp_profiles_K.append(tempProfile_cutoff[:])\n",
    "\n",
    "            V_aligned = coarseVol; T_aligned = tempProfile_cutoff\n",
    "            if z_offset_mm > 0:\n",
    "                if z_offset_mm >= len(T_aligned): T_aligned = []\n",
    "                else: T_aligned = T_aligned[z_offset_mm:]\n",
    "            elif z_offset_mm < 0:\n",
    "                 if abs(z_offset_mm) >= len(V_aligned): V_aligned = []\n",
    "                 else: V_aligned = V_aligned[abs(z_offset_mm):]\n",
    "            final_len = min(len(V_aligned), len(T_aligned))\n",
    "            if final_len == 0: n.append(np.nan); n_error_list.append(np.nan); continue # Append NaN\n",
    "\n",
    "            V_arr = np.array(V_aligned[:final_len]); T_arr = np.array(T_aligned[:final_len])\n",
    "            if i >= len(P_Pa): n.append(np.nan); n_error_list.append(np.nan); continue\n",
    "            P = P_Pa[i]\n",
    "            if np.any(T_arr <= 0): T_arr[T_arr <= 0] = 1e-6\n",
    "            if np.isnan(P) or np.isnan(V_arr).any() or np.isnan(T_arr).any(): n.append(np.nan); n_error_list.append(np.nan); continue\n",
    "            \n",
    "            # --- Mole Calculation ---\n",
    "            nList = (P * V_arr) / (R * T_arr); \n",
    "            n_total_step = np.sum(nList)\n",
    "            n.append(n_total_step)\n",
    "            \n",
    "            # --- NEW: Uncertainty Calculation ---\n",
    "            sigma_P = P * sigma_p_percent\n",
    "            sigma_V_arr = V_arr * sigma_v_percent\n",
    "            # Simple T uncertainty model: constant value\n",
    "            # (A better model would increase error away from TCs if interpolating)\n",
    "            sigma_T_arr = np.full_like(T_arr, sigma_t_base_K) \n",
    "            \n",
    "            term_P_sq = ((n_total_step / P)**2) * (sigma_P**2)\n",
    "            term_V_sq_sum = np.sum( (P / (R * T_arr))**2 * (sigma_V_arr**2) )\n",
    "            term_T_sq_sum = np.sum( (P * V_arr / (R * T_arr**2))**2 * (sigma_T_arr**2) )\n",
    "            \n",
    "            total_variance = term_P_sq + term_V_sq_sum + term_T_sq_sum\n",
    "            sigma_n = np.sqrt(total_variance)\n",
    "            n_error_list.append(sigma_n)\n",
    "            # --- END NEW ---\n",
    "\n",
    "            if i%1000 == 0:\n",
    "                print(f\"Step {i}, Time: {Time_Hours.iloc[i]:.2f} hr, n: {n_total_step:.3e} Â± {sigma_n:.2e} mol\")\n",
    "                graphProgress['value'] = int(100*i/len(runDF)); window.update_idletasks()\n",
    "        except Exception as e: print(f\"Error loop step {i}: {e}\"); graphLabel.configure(text=f\"Error step {i}: {e}\"); n.append(np.nan); avgTempList.append(np.nan); full_temp_profiles_K.append([]); n_error_list.append(np.nan)\n",
    "    print(\"Finished main calculation loop.\")\n",
    "\n",
    "    # P_calc Calculation\n",
    "    n_start = np.nan; P_calc_MPa_list = [np.nan] * len(runDF); molar_density = np.nan\n",
    "    if p_calc_start_hr is not None:\n",
    "        try:\n",
    "            start_index_loc = (Time_Hours - p_calc_start_hr).abs().idxmin()\n",
    "            if 0 <= start_index_loc < len(n):\n",
    "                n_start = n[start_index_loc]; actual_start_time = Time_Hours.iloc[start_index_loc]\n",
    "                print(f\"n_start idx {start_index_loc} (Time: {actual_start_time:.3f} hr): {n_start:.4e} mol\")\n",
    "                if pd.isna(n_start): print(\"Warn: n_start is NaN.\"); graphLabel.configure(text=\"Warn: n_start is NaN.\")\n",
    "                elif V_total_m3 <= 0: print(\"Warn: Total vol <= 0.\"); graphLabel.configure(text=\"Warn: Total volume <= 0.\")\n",
    "                else:\n",
    "                     molar_density = n_start / V_total_m3; print(f\"Initial Molar Density: {molar_density:.4e} mol/m^3\"); print(\"Calculating P_calc...\")\n",
    "                     P_calc_MPa_list = []\n",
    "                     for i in range(len(full_temp_profiles_K)):\n",
    "                         temp_prof_K = full_temp_profiles_K[i]; T_aligned = temp_prof_K; V_aligned_ref = coarseVol\n",
    "                         if z_offset_mm > 0:\n",
    "                             if z_offset_mm >= len(temp_prof_K): T_aligned = []\n",
    "                             else: T_aligned = temp_prof_K[z_offset_mm:]\n",
    "                         elif z_offset_mm < 0:\n",
    "                              if abs(z_offset_mm) >= len(coarseVol): V_aligned_ref = []\n",
    "                              else: V_aligned_ref = coarseVol[abs(z_offset_mm):]\n",
    "                         final_len_pcalc = min(len(T_aligned), len(V_aligned_ref))\n",
    "                         if final_len_pcalc == 0: P_calc_MPa_list.append(np.nan); continue\n",
    "                         T_arr_pcalc = np.array(T_aligned[:final_len_pcalc])\n",
    "                         if np.any(T_arr_pcalc <= 0): T_arr_pcalc[T_arr_pcalc <= 0] = 1e-6\n",
    "                         if np.isnan(T_arr_pcalc).any(): P_calc_MPa_list.append(np.nan); continue\n",
    "                         P_slice_Pa = molar_density * R * T_arr_pcalc; P_calc_Pa = np.nanmean(P_slice_Pa)\n",
    "                         if pd.isna(P_calc_Pa): P_calc_MPa_list.append(np.nan)\n",
    "                         else: P_calc_MPa_list.append(P_calc_Pa / 1e6)\n",
    "                     print(\"Finished P_calc.\")\n",
    "            else: print(f\"Warn: P_calc start index OOB.\"); graphLabel.configure(text=\"Warn: P_calc start index OOB.\")\n",
    "        except Exception as e: print(f\"Error P_calc prep: {e}\"); graphLabel.configure(text=f\"Error P_calc start: {e}\")\n",
    "\n",
    "    # Show Moles Plot\n",
    "    try: n_array=np.array(n); time_h_array=np.array(Time_Hours); mask_n_plot=~np.isnan(n_array); fig_n=go.Figure(); fig_n.add_trace(go.Scatter(x=time_h_array[mask_n_plot], y=n_array[mask_n_plot], name='Moles')); fig_n.update_layout(title=\"Moles vs Time\", xaxis_title=\"Time (Hr)\"); fig_n.show()\n",
    "    except Exception as e: print(f\"Plotly plot error: {e}\")\n",
    "\n",
    "    # Prepare Final Data\n",
    "    rawData, baseline, baselineRange, baselineUnit, movingAvg, movingAvgRange, movingAvgUnit, tempRange, pressureRange, timeRange, nRange, dn_dtRange = (None,)*12\n",
    "    final_expected_len = len(runDF)\n",
    "    n_final = n + [np.nan] * (final_expected_len - len(n)); n_error_final = n_error_list + [np.nan] * (final_expected_len - len(n_error_list)) # <-- Pad errors\n",
    "    avgTempList_final = avgTempList + [np.nan] * (final_expected_len - len(avgTempList))\n",
    "    P_MPa_final = P_MPa + [np.nan] * (final_expected_len - len(P_MPa)); P_calc_MPa_final = P_calc_MPa_list + [np.nan] * (final_expected_len - len(P_calc_MPa_list))\n",
    "    Time_Seconds_final = Time_Seconds.tolist() + [np.nan] * (final_expected_len - len(Time_Seconds)); Time_Minutes_final = Time_Minutes + [np.nan] * (final_expected_len - len(Time_Minutes)); Time_Hours_final = Time_Hours.tolist() + [np.nan] * (final_expected_len - len(Time_Hours))\n",
    "    control_tc_channel = \"N/A\"; control_temp_final = [np.nan] * final_expected_len\n",
    "    if TC_df is not None and 'IO Type' in TC_df.columns:\n",
    "        control_row = TC_df[TC_df['IO Type'].astype(str).str.strip().str.lower() == 'control']\n",
    "        if not control_row.empty:\n",
    "            control_tc_channel = control_row['NI LV Channel'].iloc[0]\n",
    "            if runDF is not None and control_tc_channel in runDF.columns:\n",
    "                control_data_raw = runDF[control_tc_channel]; control_data_numeric = pd.to_numeric(control_data_raw, errors='coerce').tolist(); control_temp_final = control_data_numeric + [np.nan] * (final_expected_len - len(control_data_numeric))\n",
    "    plot_df = pd.DataFrame({'Time_Hours': Time_Hours_final,'Moles_mol': n_final,'Moles_Uncertainty_mol': n_error_final, 'Pressure_Meas_MPa': P_MPa_final,'Pressure_Calc_MPa': P_calc_MPa_final,'Temp_Avg_C': avgTempList_final,'Temp_Control_C': control_temp_final,'Control_TC_Channel': control_tc_channel}) # <-- Added Uncertainty\n",
    "    if not (len(Time_Hours_final) == len(n_final) == len(P_MPa_final) == len(avgTempList_final) == len(P_calc_MPa_final) == len(n_error_final)): # <-- Added error length check\n",
    "         print(\"Error: Length mismatch FINAL.\"); graphLabel.configure(text=\"Error: Final length mismatch.\"); return\n",
    "    runData = [Time_Hours_final, Time_Minutes_final, Time_Seconds_final, n_final, P_MPa_final, avgTempList_final, runDF, TC_df, lookupTable, rawData, baseline, baselineRange, baselineUnit, baselineEdited, movingAvg, movingAvgRange, movingAvgUnit, df, data_filename, tempRange, pressureRange, timeRange, nRange, dn_dtRange, P_calc_MPa_final, full_temp_profiles_K, coarseVol, plot_df, n_error_final] # <-- Added n_error_final (item 28)\n",
    "\n",
    "    # Call moleGraph\n",
    "    try: moleGraph(runData)\n",
    "    except Exception as e: graphLabel.configure(text=f\"Error plotting: {e}\"); print(f\"Error moleGraph: {e}\"); import traceback; traceback.print_exc(); return\n",
    "    fileProgress['value'] = 100; graphProgress['value'] = 100; fileProgress.grid_forget()\n",
    "    graphLabel.configure(text=\"Graph Generated Successfully\")\n",
<<<<<<< Updated upstream
    "    if exportPlotButton: exportPlotButton.configure(state='normal')\n",
    "    if exportTempButton: exportTempButton.configure(state='normal')\n",
    "    if tempViewButton: tempViewButton.configure(state='normal')\n",
    "    if calculateFitButton: calculateFitButton.configure(state='normal')\n",
=======
>>>>>>> Stashed changes
    "    window.update_idletasks()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 12,
   "id": "befd6f99-da4d-453c-b4bd-9ca39bf9c833",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 8,
   "id": "065b94e2-7184-4f28-8565-1a8a7a21c792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID 251001TG_CalTemp\n",
      "EXP ID EXP_H_250414_CV1_A2\n",
      "running getData\n",
      "C:\\Users\\mats-collab\\Lehigh University Dropbox\\ENG-MATSGroup\\MATS\\cRIO\\RunConfig\\EXPs\\\\EXP_H_250414_CV1_A2.csv\n",
      "TC Positions (raw):\n",
      "0     246.0\n",
      "1     195.0\n",
      "2     195.0\n",
      "3     157.0\n",
      "4     157.0\n",
      "5     157.0\n",
      "6     120.0\n",
      "7     120.0\n",
      "8      69.0\n",
      "9       NaN\n",
      "10      NaN\n",
      "Name: X Position, dtype: float64\n",
      "TC_positions (valid & sorted):\n",
      "8     69\n",
      "6    120\n",
      "7    120\n",
      "3    157\n",
      "4    157\n",
      "5    157\n",
      "1    195\n",
      "2    195\n",
      "0    246\n",
      "Name: X Position, dtype: int32\n",
      "TC_df (valid TCs):\n",
      "  Device Type NI LV Channel    Shorthand Tag  X Position\n",
      "8          TC      CV1-TC38    T1-TC-69(180)          69\n",
      "6          TC      CV1-TC48     T1-TC-120(0)         120\n",
      "7          TC      CV1-TC36   T1-TC-120(180)         120\n",
      "3          TC      CV1-TC47     T1-TC-157(0)         157\n",
      "4          TC      CV1-TC34  T1-TC-157(180)*         157\n",
      "5          TC      CV1-TC34  T1-TC-157(180)*         157\n",
      "1          TC      CV1-TC46     T1-TC-195(0)         195\n",
      "2          TC      CV1-TC32   T1-TC-195(180)         195\n",
      "0          TC      CV1-TC30   T1-TC-246(180)         246\n",
      "Resetting runDF index...\n",
      "runDF index reset. New Index: RangeIndex(start=0, stop=140801, step=1)\n",
      "Using pressure column: CVFP-PT-CV-A2\n",
      "Pressure\n",
      "140801\n",
      "Minutes\n",
      "140801\n",
      "UID contains AC, GKT or GPA - using normal orientation\n",
      "Reversed orientation used for NZ-TI to honor top-most plane\n",
      "Preferring NORMAL to honor topmost previous-plane\n",
      "UID contains AC, GKT or GPA - using normal orientation\n",
      "Reversed orientation used for CRU-Zr-D\n",
      "Error processing part 9 (VRE-Mo-14 mating with LID-Zr-D): No valid mates for VRE-Mo-14 to LID-Zr-D. Halting program.\n"
     ]
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "# --- moleGraph function ---\n",
    "def moleGraph(runData):\n",
    "    global runBool, imageViewer, baselineEdited\n",
    "    [Time_Hours, Time_Minutes, Time_Seconds, n, P_MPa, avgTempList, runDF, TC_df, lookupTable,\n",
    "     rawData, baseline, baselineRange, baselineUnit, baselineEdited, movingAvg, movingAvgRange,\n",
    "     movingAvgUnit, df, fileName, tempRange, pressureRange, timeRange, nRange, dn_dtRange,\n",
    "     P_calc_MPa, full_temp_profiles_K, coarseVol, plot_df, n_error] = runData # <-- Unpack 29 items\n",
    "    if runBool==True:\n",
    "        if imageViewer and imageViewer.winfo_exists(): imageViewer.destroy()\n",
    "    runBool=True\n",
    "    imageViewer = Toplevel(window); imageViewer.title(str(fileName)); imageViewer.geometry(\"1000x600\")\n",
    "    fig, ax1 = plt.subplots(); fig.subplots_adjust(right=0.75)\n",
    "    \n",
    "    n_error_np = None # Initialize\n",
    "    \n",
    "    if plot_df is not None and isinstance(plot_df, pd.DataFrame):\n",
    "        time_h_np = plot_df['Time_Hours'].to_numpy(); n_np = plot_df['Moles_mol'].to_numpy(); p_mpa_np = plot_df['Pressure_Meas_MPa'].to_numpy()\n",
    "        p_calc_mpa_np = plot_df['Pressure_Calc_MPa'].to_numpy(); avg_temp_np = plot_df['Temp_Avg_C'].to_numpy(); control_tc_data_numeric = plot_df['Temp_Control_C'].to_numpy()\n",
    "        n_error_np = plot_df['Moles_Uncertainty_mol'].to_numpy() # <-- Get error from df\n",
    "        control_tc_channel = plot_df['Control_TC_Channel'].iloc[0] if not plot_df.empty else \"N/A\"\n",
    "        mask_n = ~np.isnan(n_np); mask_p = ~np.isnan(p_mpa_np); mask_t = ~np.isnan(avg_temp_np); mask_p_calc = ~np.isnan(p_calc_mpa_np); mask_control_t = ~np.isnan(control_tc_data_numeric)\n",
    "        time_control_t = time_h_np[mask_control_t] if np.any(mask_control_t) else np.array([])\n",
    "        print(f\"Plotting from {'imported' if TC_df is None else 'calculated'} data. Control TC: {control_tc_channel}\")\n",
    "    else:\n",
    "        time_h_np = np.array(Time_Hours); n_np = np.array(n); p_mpa_np = np.array(P_MPa); avg_temp_np = np.array(avgTempList); p_calc_mpa_np = np.array(P_calc_MPa)\n",
    "        n_error_np = np.array(n_error) # <-- Get error from list\n",
    "        control_tc_channel = None; control_tc_data_numeric = None; mask_control_t = np.array([False]*len(time_h_np)); time_control_t = np.array([])\n",
    "        if TC_df is not None and 'IO Type' in TC_df.columns and 'NI LV Channel' in TC_df.columns:\n",
    "            control_row = TC_df[TC_df['IO Type'].astype(str).str.strip().str.lower() == 'control']\n",
    "            if not control_row.empty:\n",
    "                control_tc_channel = control_row['NI LV Channel'].iloc[0]; print(f\"Found Control TC: {control_tc_channel}\")\n",
    "                if runDF is not None and control_tc_channel in runDF.columns:\n",
    "                     control_tc_data_raw = runDF[control_tc_channel]; control_tc_data_numeric = pd.to_numeric(control_tc_data_raw, errors='coerce').to_numpy();\n",
    "                     current_len = min(len(control_tc_data_numeric), len(time_h_np)); mask_control_t = ~np.isnan(control_tc_data_numeric[:current_len])\n",
    "                     if np.any(mask_control_t): time_control_t = time_h_np[:current_len][mask_control_t]\n",
    "                else: print(f\"Warn: Control TC '{control_tc_channel}' not in final runDF.\")\n",
    "            else: print(\"Warn: No 'Control' TC. Plotting avg temp.\")\n",
    "        else: print(\"Warn: Cannot determine Control TC. Plotting avg temp.\")\n",
    "        mask_n = ~np.isnan(n_np); mask_p = ~np.isnan(p_mpa_np); mask_t = ~np.isnan(avg_temp_np); mask_p_calc = ~np.isnan(p_calc_mpa_np)\n",
    "    \n",
    "    # Create mask for uncertainty\n",
    "    mask_err = ~np.isnan(n_error_np)\n",
    "    mask_n_with_err = mask_n & mask_err # Combined mask for plotting error band\n",
    "    \n",
    "    time_h_n = time_h_np[mask_n] if np.any(mask_n) else np.array([]); time_h_p = time_h_np[mask_p] if np.any(mask_p) else np.array([])\n",
    "    time_h_t = time_h_np[mask_t] if np.any(mask_t) else np.array([]); time_h_p_calc = time_h_np[mask_p_calc] if np.any(mask_p_calc) else np.array([])\n",
    "    time_h_err = time_h_np[mask_n_with_err] if np.any(mask_n_with_err) else np.array([]) # Time for error band\n",
    "    \n",
    "    handles = []; labels = []\n",
    "    if time_h_n.size > 0: \n",
    "        p1, = ax1.plot(time_h_n, n_np[mask_n], color='blue', label='n (mol)'); handles.append(p1); labels.append('n (mol)')\n",
    "        # --- NEW: Plot Error Band ---\n",
    "        if time_h_err.size > 0:\n",
    "             n_plus_sigma = n_np[mask_n_with_err] + n_error_np[mask_n_with_err]\n",
    "             n_minus_sigma = n_np[mask_n_with_err] - n_error_np[mask_n_with_err]\n",
    "             ax1.fill_between(time_h_err, n_minus_sigma, n_plus_sigma, color='blue', alpha=0.2, label=r'n (1$\\sigma$ Uncertainty)')\n",
    "             # Add to legend manually? fill_between doesn't add a handle easily\n",
    "             handles.append(plt.Rectangle((0,0), 1, 1, fc='blue', alpha=0.2)); labels.append(r'n (1$\\sigma$ Uncertainty)')\n",
    "        # --- END NEW ---\n",
    "    ax1.set_xlabel(\"Time (Hours)\"); ax1.set_ylabel(\"n (mol)\", color='blue'); ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    ax2 = ax1.twinx()\n",
    "    if time_h_p.size > 0: p2, = ax2.plot(time_h_p, p_mpa_np[mask_p], color='red', label='P_meas (MPa)'); handles.append(p2); labels.append('P_meas (MPa)')\n",
    "    if time_h_p_calc.size > 0: p_calc_plot, = ax2.plot(time_h_p_calc, p_calc_mpa_np[mask_p_calc], color='darkorange', linestyle='--', label='P_calc (MPa)'); handles.append(p_calc_plot); labels.append('P_calc (MPa)')\n",
    "    ax2.set_ylabel(\"Pressure (MPa)\", color='red'); ax2.tick_params(axis='y', labelcolor='red')\n",
    "    ax3 = ax1.twinx(); temp_label_text = 'Avg T (C)'\n",
    "    safe_mask_control_t = mask_control_t[:len(control_tc_data_numeric)] if control_tc_data_numeric is not None else mask_control_t\n",
    "    if control_tc_channel != \"N/A\" and control_tc_data_numeric is not None and time_control_t.size > 0:\n",
    "        safe_len = min(len(control_tc_data_numeric), len(safe_mask_control_t)); p3, = ax3.plot(time_control_t, control_tc_data_numeric[:safe_len][safe_mask_control_t], color='green', label=f'Control T ({control_tc_channel}) (C)')\n",
    "        temp_label_text = 'Control T (C)'; handles.append(p3); labels.append(f'Control T ({control_tc_channel}) (C)')\n",
    "    elif time_h_t.size > 0: p3a, = ax3.plot(time_h_t, avg_temp_np[mask_t], color='purple', linestyle=':', label='Avg T (C)'); handles.append(p3a); labels.append('Avg T (C)')\n",
    "    ax3.set_ylabel(temp_label_text, color='green'); ax3.tick_params(axis='y', labelcolor='green'); ax3.spines['right'].set_position(('outward', 60))\n",
    "    if handles: ax1.legend(handles=handles, labels=labels, loc=0)\n",
    "    imageFrame = Frame(imageViewer); imageFrame.grid(row=2, column=1); canvas = FigureCanvasTkAgg(fig, master=imageFrame); canvas.draw(); canvas.get_tk_widget().grid(row=1, column=1)\n",
    "    toolbarFrame = Frame(imageViewer); toolbarFrame.grid(row=1, column=1); NavigationToolbar2Tk(canvas, toolbarFrame)\n",
    "    baselineEdited = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae61337b-6520-44de-a0c5-0f17dd659fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Temperature Profile Viewer Functions ---\n",
    "def open_temp_viewer():\n",
    "    global runData, temp_viewer_window, graphLabel\n",
    "    if not runData or len(runData) < 29: graphLabel.configure(text=\"Error: Run 'Generate Graph' first.\"); return\n",
    "    if runData[25] is None or runData[26] is None: graphLabel.configure(text=\"Error: Temp profiles N/A.\"); return\n",
    "    if temp_viewer_window and temp_viewer_window.winfo_exists(): temp_viewer_window.lift(); return\n",
    "    try: time_hours_list = runData[0]; full_profiles = runData[25]; coarse_vol = runData[26]\n",
    "    except IndexError: graphLabel.configure(text=\"Error: runData missing profile info.\"); return\n",
    "    temp_viewer_window = tk.Toplevel(window); temp_viewer_window.title(\"Temperature Profile Viewer\"); temp_viewer_window.geometry(\"800x600\")\n",
    "    control_frame = tk.Frame(temp_viewer_window); control_frame.pack(side=tk.TOP, fill=tk.X, pady=5, padx=5)\n",
    "    tk.Label(control_frame, text=f\"Time Step Index (0 to {len(full_profiles)-1}):\").pack(side=tk.LEFT, padx=5)\n",
    "    step_index_var = tk.StringVar(value='0'); step_entry = tk.Entry(control_frame, textvariable=step_index_var, width=10); step_entry.pack(side=tk.LEFT, padx=5)\n",
    "    plot_frame = tk.Frame(temp_viewer_window); plot_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "    fig_temp = plt.figure(); canvas_temp = FigureCanvasTkAgg(fig_temp, master=plot_frame); canvas_temp.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "    toolbar_temp = NavigationToolbar2Tk(canvas_temp, plot_frame); toolbar_temp.update(); toolbar_temp.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "    def plot_specific_temp_profile():\n",
    "        global runData\n",
    "        plot_error_label = None\n",
    "        for widget in control_frame.winfo_children():\n",
    "             if isinstance(widget, tk.Label) and widget.cget('fg') == 'red': widget.destroy()\n",
    "        try:\n",
    "            full_profiles = runData[25]; coarse_vol = runData[26]; time_hours_list = runData[0]\n",
    "            idx_str = step_index_var.get(); idx = int(idx_str)\n",
    "            if not (0 <= idx < len(full_profiles)): tk.Label(control_frame, text=f\"Index {idx} OOB\", fg='red').pack(side=tk.LEFT); return\n",
    "            profile_K = full_profiles[idx]; current_time_hr = time_hours_list[idx]\n",
    "            if not profile_K: tk.Label(control_frame, text=f\"No profile data idx {idx}\", fg='orange').pack(side=tk.LEFT); return\n",
    "            fig_temp.clear(); axT = fig_temp.add_subplot(111); axV = axT.twinx()\n",
    "            x_axis = np.arange(len(profile_K)); pT, = axT.plot(x_axis, profile_K, color='blue', label='Temp (K)')\n",
    "            axT.set_xlabel(\"Z Position (mm)\"); axT.set_ylabel(\"Temperature (K)\", color='blue'); axT.tick_params(axis='y', labelcolor='blue')\n",
    "            vol_to_plot = coarse_vol[:len(profile_K)]; x_vol = np.arange(len(vol_to_plot))\n",
    "            pV, = axV.plot(x_vol, vol_to_plot, color='red', linestyle='--', alpha=0.5, label='Volume (m^3)')\n",
    "            axV.set_ylabel(\"Volume (m^3)\", color='red'); axV.tick_params(axis='y', labelcolor='red')\n",
    "            axT.set_title(f\"Profile @ Idx {idx} (T: {current_time_hr:.3f} Hr)\")\n",
    "            fig_temp.legend(handles=[pT, pV], loc='upper right'); canvas_temp.draw()\n",
    "        except ValueError: tk.Label(control_frame, text=\"Invalid index.\", fg='red').pack(side=tk.LEFT)\n",
    "        except Exception as e: print(f\"Plot viewer error: {e}\"); tk.Label(control_frame, text=f\"Plot Error: {e}\", fg='red').pack(side=tk.LEFT)\n",
    "    plot_button = tk.Button(control_frame, text=\"Plot Profile\", command=plot_specific_temp_profile); plot_button.pack(side=tk.LEFT, padx=10)\n",
    "    plot_specific_temp_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d9c5b1f-08bd-409c-aafa-5f552771783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Export Temp Profiles Function ---\n",
    "def export_temp_profiles():\n",
    "    global runData, graphLabel\n",
    "    if not runData or len(runData) < 29: graphLabel.configure(text=\"Error: Run 'Generate Graph' first.\"); return\n",
    "    if runData[25] is None: graphLabel.configure(text=\"Error: Temp profiles N/A.\"); return\n",
    "    try:\n",
    "        time_hours_list = runData[0]; full_profiles = runData[25]\n",
    "        use_interpolation = runData[8] is None\n",
    "        tc_positions = runData[7]['X Position'] if runData[7] is not None else None\n",
    "        if not time_hours_list or not full_profiles: graphLabel.configure(text=\"Error: Time/profile data empty.\"); return\n",
    "        max_len = 0; start_z = 0\n",
    "        if full_profiles: max_len = max(len(p) for p in full_profiles if p)\n",
    "        if use_interpolation and tc_positions is not None and not tc_positions.empty: start_z = int(tc_positions.min())\n",
    "        elif not use_interpolation and runData[8] is not None:\n",
    "            try: start_z = int(runData[8].columns[1])\n",
    "            except (IndexError, ValueError): start_z = 0\n",
    "        if max_len == 0: graphLabel.configure(text=\"Error: Profiles empty.\"); return\n",
    "        file_path = filedialog.asksaveasfilename(title=\"Save Temp Profiles CSV\", defaultextension=\".csv\", filetypes=((\"CSV files\", \"*.csv\"),))\n",
    "        if not file_path: graphLabel.configure(text=\"Export cancelled.\"); return\n",
    "        headers = [\"Time_Hours\"] + [f\"Z_{start_z + z}_mm\" for z in range(max_len)]\n",
    "        data_to_export = []\n",
    "        for i in range(len(time_hours_list)):\n",
    "            time_val = time_hours_list[i]; profile = full_profiles[i] if i < len(full_profiles) else []\n",
    "            padded_profile = profile + [np.nan] * (max_len - len(profile)); data_to_export.append([time_val] + padded_profile)\n",
    "        export_df = pd.DataFrame(data_to_export, columns=headers)\n",
    "        export_df.to_csv(file_path, index=False, float_format='%.3f')\n",
    "        graphLabel.configure(text=f\"Temp profiles exported.\")\n",
    "    except Exception as e: print(f\"Error exporting profiles: {e}\"); graphLabel.configure(text=f\"Error exporting profiles: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "304acd93-e6bf-4d26-93b6-a6be2c63958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Export Plot Data Function ---\n",
    "def export_plot_data():\n",
    "    global runData, graphLabel\n",
    "    if not runData or len(runData) < 29: graphLabel.configure(text=\"Error: Run 'Generate Graph' first.\"); return\n",
    "    plot_df = runData[27]\n",
    "    if not isinstance(plot_df, pd.DataFrame): graphLabel.configure(text=\"Error: plot_df missing.\"); return\n",
    "    try:\n",
    "        file_path = filedialog.asksaveasfilename(title=\"Save Plot Data CSV\", defaultextension=\".csv\", filetypes=((\"CSV files\", \"*.csv\"),))\n",
    "        if not file_path: graphLabel.configure(text=\"Export cancelled.\"); return\n",
    "        plot_df.to_csv(file_path, index=False, float_format='%.6e')\n",
    "        graphLabel.configure(text=f\"Plot data exported.\")\n",
    "    except Exception as e: print(f\"Error exporting plot data: {e}\"); graphLabel.configure(text=f\"Error exporting plot data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab0964d3-ed4a-4844-9627-490a5d9ee8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Data Function ---\n",
    "def import_data():\n",
    "    global runData, graphLabel, tempViewButton, exportTempButton, exportPlotButton, calculateFitButton\n",
    "    try:\n",
    "        file_path = filedialog.askopenfilename(title=\"Import Plot Data CSV\", filetypes=((\"CSV files\", \"*.csv\"),))\n",
    "        if not file_path: graphLabel.configure(text=\"Import cancelled.\"); return\n",
    "        imported_df = pd.read_csv(file_path)\n",
    "        required_cols = ['Time_Hours', 'Moles_mol', 'Moles_Uncertainty_mol', 'Pressure_Meas_MPa', 'Pressure_Calc_MPa', 'Temp_Avg_C', 'Temp_Control_C', 'Control_TC_Channel']\n",
    "        if not all(col in imported_df.columns for col in required_cols): graphLabel.configure(text=f\"Error: Imported CSV missing columns.\"); print(f\"Missing: {[c for c in required_cols if c not in imported_df.columns]}\"); return\n",
    "        Time_Hours_final = imported_df['Time_Hours'].tolist(); n_final = imported_df['Moles_mol'].tolist()\n",
    "        P_MPa_final = imported_df['Pressure_Meas_MPa'].tolist(); P_calc_MPa_final = imported_df['Pressure_Calc_MPa'].tolist()\n",
    "        avgTempList_final = imported_df['Temp_Avg_C'].tolist(); control_temp_final = imported_df['Temp_Control_C'].tolist()\n",
    "        n_error_final = imported_df['Moles_Uncertainty_mol'].tolist() # <-- Import uncertainty\n",
    "        control_tc_channel = imported_df['Control_TC_Channel'].iloc[0] if not imported_df.empty else \"N/A\"\n",
    "        mock_runDF = pd.DataFrame({control_tc_channel: control_temp_final}) if control_tc_channel != \"N/A\" else pd.DataFrame()\n",
    "        mock_TC_df = pd.DataFrame({'NI LV Channel': [control_tc_channel], 'IO Type': ['Control']}) if control_tc_channel != \"N/A\" else pd.DataFrame()\n",
    "        mock_runData = [Time_Hours_final,None,None,n_final,P_MPa_final,avgTempList_final,mock_runDF,mock_TC_df,None,None,None,None,None,None,None,None,None,None,file_path,None,None,None,None,None,P_calc_MPa_final,None,None,imported_df,n_error_final] # <-- Add error to list\n",
    "        runData = mock_runData\n",
    "        if tempViewButton: tempViewButton.configure(state='disabled')\n",
    "        if exportTempButton: exportTempButton.configure(state='disabled')\n",
    "        if exportPlotButton: exportPlotButton.configure(state='normal')\n",
    "        if calculateFitButton: calculateFitButton.configure(state='normal')\n",
    "        moleGraph(mock_runData)\n",
    "        graphLabel.configure(text=f\"Imported & plotted: {os.path.basename(file_path)}\")\n",
    "    except Exception as e: print(f\"Error importing data: {e}\"); import traceback; traceback.print_exc(); graphLabel.configure(text=f\"Error importing data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "849bce07-a828-492e-949d-c54600cd5f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Temp Profile Viewer Function ---\n",
    "def import_temp_profile_viewer():\n",
    "    global graphLabel, temp_viewer_window\n",
    "    try:\n",
    "        file_path = filedialog.askopenfilename(title=\"Import Temperature Profile CSV\", filetypes=((\"CSV files\", \"*.csv\"),))\n",
    "        if not file_path: graphLabel.configure(text=\"Import cancelled.\"); return\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'Time_Hours' not in df.columns: graphLabel.configure(text=\"Error: Imported CSV missing 'Time_Hours'.\"); return\n",
    "        z_cols = [col for col in df.columns if col.startswith('Z_') and col.endswith('_mm')]\n",
    "        if not z_cols: graphLabel.configure(text=\"Error: Imported CSV missing 'Z_..._mm' cols.\"); return\n",
    "        y_axis_time = df['Time_Hours']\n",
    "        z_col_nums = sorted([(int(re.findall(r'\\d+', col)[0]), col) for col in z_cols]); x_axis_z_positions = [z[0] for z in z_col_nums]; sorted_z_cols = [z[1] for z in z_col_nums]\n",
    "        z_data_temps = df[sorted_z_cols].values\n",
    "        \n",
    "        if temp_viewer_window and temp_viewer_window.winfo_exists(): temp_viewer_window.destroy()\n",
    "        temp_viewer_window = tk.Toplevel(window); temp_viewer_window.title(f\"Imported Profile: {os.path.basename(file_path)}\"); temp_viewer_window.geometry(\"800x600\")\n",
    "        \n",
    "        fig_temp = plt.figure(); ax = fig_temp.add_subplot(111)\n",
    "        im = ax.imshow(z_data_temps, aspect='auto', cmap='jet', extent=[min(x_axis_z_positions), max(x_axis_z_positions), y_axis_time.max(), y_axis_time.min()])\n",
    "        ax.set_title(f\"Temperature Profile (T vs. Z vs. Time)\"); ax.set_xlabel(\"Z Position (mm)\"); ax.set_ylabel(\"Time (Hours)\")\n",
    "        fig_temp.colorbar(im, ax=ax, label=\"Temp (K?)\")\n",
    "        \n",
    "        plot_frame = tk.Frame(temp_viewer_window); plot_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "        canvas_temp = FigureCanvasTkAgg(fig_temp, master=plot_frame); canvas_temp.draw(); canvas_temp.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "        toolbar_temp = NavigationToolbar2Tk(canvas_temp, plot_frame); toolbar_temp.update(); toolbar_temp.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        graphLabel.configure(text=f\"Temp profile viewer opened for {os.path.basename(file_path)}\")\n",
    "    except Exception as e: print(f\"Error importing temp profile: {e}\"); import traceback; traceback.print_exc(); graphLabel.configure(text=f\"Error importing temp profile: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7a89b96-f536-4a18-ae7b-aa91247b2546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate Exponential Fit Function ---\n",
    "def exp_fit_func(t, a, b, c):\n",
    "    \"\"\"Exponential decay function: a * exp(-b * t) + c\"\"\"\n",
    "    return a * np.exp(-b * t) + c\n",
    "\n",
    "def calculate_exponential_fit():\n",
    "    global runData, fit_start_time_var, fit_end_time_var, fit_results_label\n",
    "    \n",
    "    if not runData or len(runData) < 29: # Check for 29 items\n",
    "        fit_results_label.configure(text=\"Error: Must 'Generate Graph' or 'Import' data first.\", fg='red')\n",
    "        return\n",
    "        \n",
    "    plot_df = runData[27] # plot_df is at index 27\n",
    "    if not isinstance(plot_df, pd.DataFrame) or 'Moles_Uncertainty_mol' not in plot_df.columns:\n",
    "        fit_results_label.configure(text=\"Error: Plot data/Uncertainty is missing. Re-run/Re-import.\", fg='red')\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        start_h = float(fit_start_time_var.get())\n",
    "        end_h = float(fit_end_time_var.get())\n",
    "        if start_h >= end_h:\n",
    "            fit_results_label.configure(text=\"Error: Start time must be before end time.\", fg='red')\n",
    "            return\n",
    "    except ValueError:\n",
    "        fit_results_label.configure(text=\"Error: Fit times must be numeric (e.g., 1.5).\", fg='red')\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df_fit = plot_df[(plot_df['Time_Hours'] >= start_h) & (plot_df['Time_Hours'] <= end_h)].copy()\n",
    "        df_fit.dropna(subset=['Time_Hours', 'Pressure_Meas_MPa', 'Temp_Control_C', 'Moles_mol', 'Moles_Uncertainty_mol'], inplace=True)\n",
    "        \n",
    "        if len(df_fit) < 3:\n",
    "            fit_results_label.configure(text=\"Error: Not enough valid data points in selected range.\", fg='red')\n",
    "            return\n",
    "\n",
    "        t_data = df_fit['Time_Hours']; t_data_rel = t_data - t_data.iloc[0]; p_data = df_fit['Pressure_Meas_MPa']; t_control_data = df_fit['Temp_Control_C']\n",
    "        p0 = [p_data.iloc[0] - p_data.iloc[-1], 1.0, p_data.iloc[-1]]\n",
    "        \n",
    "        print(f\"Fitting {len(t_data_rel)} points between {start_h} and {end_h} Hr...\"); print(f\"Initial guesses (a, b, c): {p0}\")\n",
    "        popt, pcov = curve_fit(exp_fit_func, t_data_rel, p_data, p0=p0, maxfev=5000)\n",
    "        \n",
    "        asymptote_c = popt[2]; temp_at_end = t_control_data.iloc[-1]\n",
    "        \n",
    "        # --- NEW: LOD Calculation ---\n",
    "        delta_n_measured = df_fit['Moles_mol'].iloc[-1] - df_fit['Moles_mol'].iloc[0]\n",
    "        sigma_n_start = df_fit['Moles_Uncertainty_mol'].iloc[0]\n",
    "        sigma_n_end = df_fit['Moles_Uncertainty_mol'].iloc[-1]\n",
    "        \n",
    "        sigma_delta_n = np.sqrt(sigma_n_start**2 + sigma_n_end**2)\n",
    "        LOD_3sigma_mol = 3 * sigma_delta_n\n",
    "        # --- END NEW ---\n",
    "\n",
    "        result_text = r\"Fit Asymptote: {asymptote_c:.4e} MPa | Control T @ {end_h:.2f} Hr: {temp_at_end:.2f} C\\n\"\n",
    "        result_text += r\"Measured $\\Delta n$: {delta_n_measured:.3e} mol | LOD (3$\\sigma$): {LOD_3sigma_mol:.3e} mol\"\n",
    "        \n",
    "        fit_results_label.configure(text=result_text, fg='black')\n",
    "        print(result_text)\n",
    "\n",
    "    except RuntimeError:\n",
    "        fit_results_label.configure(text=\"Error: Exponential fit failed to converge.\", fg='red')\n",
    "        print(\"Error: Exponential fit failed to converge.\")\n",
    "    except Exception as e:\n",
    "        fit_results_label.configure(text=f\"Error: {e}\", fg='red')\n",
    "        print(f\"Error during fitting: {e}\")\n",
    "        import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac7fad-b35d-43b3-a713-32ea36175d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN GUI ---\n",
    "window=tk.Tk(); window.title(\"MoleGrapher 1.4.0\"); window.geometry(\"500x580\") # Updated title/size\n",
    "graphLabel = tk.Label(window, text = \"Press 'Generate Graph' or 'Import...' to begin.\", width = 100, anchor=W); graphLabel.grid(row=1, column=1, columnspan=5, sticky=W)\n",
    "\n",
    "# Row 11: File Browsing/Import\n",
    "importPlotButton = tk.Button(window, text=\"Import Plot CSV\", command=import_data, anchor=W); importPlotButton.grid(row=11, column=1, sticky=W)\n",
    "importTempButton = tk.Button(window, text=\"Import Temp CSV\", command=import_temp_profile_viewer, anchor=W); importTempButton.grid(row=11, column=2, sticky=W)\n",
    "fileBrowseButton = tk.Button(window, text=\"Browse Data...\", command=lambda: browseFiles(), anchor=W); fileBrowseButton.grid(row=11, column=3, sticky=W)\n",
    "fileLabel = tk.Label(window, text=\"Data: (Not Selected)\", width=40, anchor=W); fileLabel.grid(row=11, column=4, columnspan=2, sticky=W)\n",
    "\n",
    "# Row 12: Temp Profile / Interpolation\n",
    "interpolate_temps_var = tk.BooleanVar(value=False); interpolateCheckbox = tk.Checkbutton(window, text=\"Interpolate Temps (No CSV)\", variable=interpolate_temps_var, command=toggle_temp_file_selection, anchor=W); interpolateCheckbox.grid(row=12, column=1, sticky=W)\n",
    "tempLabel = tk.Label(window, text=\"Temp Profile: (Select via Browse)\", width=100, anchor=W); tempLabel.grid(row=12, column=2, columnspan=5, sticky=W)\n",
    "\n",
    "# Rows 13-16: Geometry Files\n",
    "layoutLabel = tk.Label(window, text=\"Layout: (Not Selected)\", width=100, anchor=W); layoutLabel.grid(row=13, column=2, columnspan=5, sticky=W)\n",
    "matingLabel = tk.Label(window, text=\"Mating Table: (Not Selected)\", width=100, anchor=W); matingLabel.grid(row=14, column=2, columnspan=5, sticky=W)\n",
    "furLabel = tk.Label(window, text=\"MLD-FUR: (Not Selected)\", width=100, anchor=W); furLabel.grid(row=15, column=2, columnspan=5, sticky=W)\n",
    "hpsLabel = tk.Label(window, text=\"MLD-HPS: (Not Selected)\", width=100, anchor=W); hpsLabel.grid(row=16, column=2, columnspan=5, sticky=W)\n",
    "\n",
    "# Rows 17-19: Parameters\n",
    "zCutoffLabel = tk.Label(window, text=\"Z-Temp Cutoff (mm):\", width=25, anchor=W); zCutoffLabel.grid(row=17, column=1, sticky=W)\n",
    "z_temp_cutoff_var = tk.StringVar(value=''); zCutoffEntry = tk.Entry(window, textvariable=z_temp_cutoff_var, width=20); zCutoffEntry.grid(row=17, column=2, sticky=W)\n",
    "zOffsetLabel = tk.Label(window, text=\"Z-Offset (mm):\", width=25, anchor=W); zOffsetLabel.grid(row=18, column=1, sticky=W)\n",
    "z_offset_var = tk.StringVar(value=''); zOffsetEntry = tk.Entry(window, textvariable=z_offset_var, width=20); zOffsetEntry.grid(row=18, column=2, sticky=W)\n",
    "pCalcStartTimeLabel = tk.Label(window, text=\"P_calc Start Time (Hours):\", width=25, anchor=W); pCalcStartTimeLabel.grid(row=19, column=1, sticky=W)\n",
    "p_calc_start_time_var = tk.StringVar(value=''); pCalcStartTimeEntry = tk.Entry(window, textvariable=p_calc_start_time_var, width=20); pCalcStartTimeEntry.grid(row=19, column=2, sticky=W)\n",
    "\n",
    "# --- NEW: Row 20-21: Uncertainty Inputs ---\n",
    "sigmaPLabel = tk.Label(window, text=r\"$\\sigma_P$ (% Error):\", width=25, anchor=W); sigmaPLabel.grid(row=20, column=1, sticky=W)\n",
    "sigma_p_var = tk.StringVar(value='0.25'); sigmaPEntry = tk.Entry(window, textvariable=sigma_p_var, width=10); sigmaPEntry.grid(row=20, column=2, sticky=W)\n",
    "sigmaVLabel = tk.Label(window, text=r\"$\\sigma_V$ (% Error):\", width=25, anchor=W); sigmaVLabel.grid(row=21, column=1, sticky=W)\n",
    "sigma_v_var = tk.StringVar(value='5.0'); sigmaVEntry = tk.Entry(window, textvariable=sigma_v_var, width=10); sigmaVEntry.grid(row=21, column=2, sticky=W)\n",
    "sigmaTLabel = tk.Label(window, text=r\"$\\sigma_T$ (K Error):\", width=25, anchor=W); sigmaTLabel.grid(row=21, column=3, sticky=W)\n",
    "sigma_t_var = tk.StringVar(value='2.2'); sigmaTEntry = tk.Entry(window, textvariable=sigma_t_var, width=10); sigmaTEntry.grid(row=21, column=4, sticky=W)\n",
    "# --- END NEW ---\n",
    "\n",
    "# Row 22: Action Buttons\n",
    "graphButton=tk.Button(window, text=\"Generate Graph\", command=lambda: processData(), anchor=W); graphButton.grid(row=22, column=1, sticky=W)\n",
    "tempViewButton=tk.Button(window, text=\"View Temp Profiles\", command=open_temp_viewer, anchor=W, state='disabled'); tempViewButton.grid(row=22, column=2, sticky=W)\n",
    "exportPlotButton=tk.Button(window, text=\"Export Plot Data\", command=export_plot_data, anchor=W, state='disabled'); exportPlotButton.grid(row=22, column=3, sticky=W)\n",
    "exportTempButton = tk.Button(window, text=\"Export Temp Profiles\", command=export_temp_profiles, anchor=W, state='disabled'); exportTempButton.grid(row=22, column=4, sticky=W, padx=5)\n",
    "\n",
    "# Row 23-25: Fit Controls\n",
    "fitStartLabel = tk.Label(window, text=\"Fit Start Time (Hours):\", width=25, anchor=W); fitStartLabel.grid(row=23, column=1, sticky=W)\n",
    "fit_start_time_var = tk.StringVar(value=''); fitStartEntry = tk.Entry(window, textvariable=fit_start_time_var, width=10); fitStartEntry.grid(row=23, column=2, sticky=W)\n",
    "fitEndLabel = tk.Label(window, text=\"Fit End Time (Hours):\", width=25, anchor=W); fitEndLabel.grid(row=24, column=1, sticky=W)\n",
    "fit_end_time_var = tk.StringVar(value=''); fitEndEntry = tk.Entry(window, textvariable=fit_end_time_var, width=10); fitEndEntry.grid(row=24, column=2, sticky=W)\n",
    "calculateFitButton = tk.Button(window, text=\"Calculate Fit\", command=calculate_exponential_fit, anchor=W, state='disabled'); calculateFitButton.grid(row=23, column=3, sticky=W, rowspan=2)\n",
    "fit_results_label = tk.Label(window, text=\"\", width=100, anchor=W, height=2, justify=LEFT); fit_results_label.grid(row=25, column=1, columnspan=5, sticky=W) # Updated label\n",
    "\n",
    "# Row 26: Progress Bars\n",
    "fileProgress = Progressbar(window, orient = HORIZONTAL, length = 100, mode = 'determinate'); fileProgress.grid(row=26, column=4, sticky=E, padx=5)\n",
    "graphProgress = Progressbar(window, orient = HORIZONTAL, length = 200, mode = 'determinate'); graphProgress.grid(row=26, column=2, columnspan=2, sticky=W)\n",
    "\n",
    "window.attributes('-topmost', False)\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8da1e5-1e96-4c4d-a1fc-0385034b2863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< Updated upstream
   "version": "3.13.7"
  }
=======
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
>>>>>>> Stashed changes
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
